{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【WIP】落書き認識Webアプリを作ろう\n",
    "\n",
    "- Author: Arata Furukawa ([github](https://github.com/ornew), [facebook](https://www.facebook.com/old.r.new))\n",
    "- Contributor: Hideya Kawahara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、セミナーの資料として作成されています。ノートブックは、自由な編集、実行が可能です。Markdown形式でドキュメントも書き込めるため、必要に応じてメモを追記するなど、工夫してご利用ください。\n",
    "\n",
    "参加者の皆様には後日データを配布いたしますが、編集も含めて持ち帰りたい場合は、画面上部のツールバーから、【File】タブを選び、【Download as】を選ぶことでローカルマシン上に保存することが可能です。\n",
    "\n",
    "このノートブックはご自由にご利用頂けますが、インターネット上への無断での転載だけはご遠慮くださいますようお願いします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回、認識する落書きは、以下の10クラス(種類)です。\n",
    "\n",
    "1. りんご(apple)\n",
    "2. ベッド(bed)\n",
    "3. 猫(cat)\n",
    "4. 犬(dog)\n",
    "5. 目(eye)\n",
    "6. 魚(fish)\n",
    "7. 草(grass)\n",
    "8. 手(hand)\n",
    "9. アイスクリーム(ice cream)\n",
    "10. ジャケット(jacket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28x28ピクセルのグレースケール画像から、上記のいずれの落書きであるかを**確率的に**予測します。\n",
    "\n",
    "![](./img/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ディープラーニング\n",
    "\n",
    "モデルは(ディープ)ニューラルネットワークで実装します。\n",
    "\n",
    "ニューラルネットワークとは、生物のニューロン(神経細胞)のネットワークを数理モデルで模倣することで、特定の課題解決能力を機械的に学習する、機械学習アルゴリズムの一種です。深い層で構成されるニューラルネットワークの学習を行うことをディープラーニングといいます。\n",
    "\n",
    "ディープラーニングにおけるモデルの学習は、以下の流れで行います。\n",
    "\n",
    "0. モデルのパラメータを初期化する\n",
    "1. 学習用データに対する予測を計算する\n",
    "2. 教師ラベルと予測結果の誤差を計算する\n",
    "3. 誤差を最小化するようにモデルのパラメータを更新する\n",
    "4. **誤差が十分に小さくなるまで**1-3を繰り返す\n",
    "\n",
    "![](./img/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装の流れ\n",
    "\n",
    "このノートブックでは、以下の手順で、ディープラーニングを用いた落書き(Doodle)認識を行うWebアプリを作成します。\n",
    "\n",
    "1. [\"the Quick, Draw!\"データセット](https://quickdraw.withgoogle.com/data)を学習用データとして準備する\n",
    "2. [TensorFlow](https://www.tensorflow.org/)で落書きを認識するディープニューラルネットワークのモデルを実装する\n",
    "3. [Amazon SageMaker](https://aws.amazon.com/jp/sagemaker/)でモデルを学習する\n",
    "4. [TensorFlow.js](https://js.tensorflow.org/)を使ったWebアプリに学習済みモデルを組み込む\n",
    "5. [Amazon S3](https://aws.amazon.com/jp/s3/)でWebアプリを公開する\n",
    "\n",
    "![](./img/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず、作業に必要なモジュールを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six               # Python 2と3の互換性を保つためのライブラリです\n",
    "import numpy as np       # 行列などの科学数値計算をするためのライブラリです\n",
    "\n",
    "import matplotlib.pyplot as plt # グラフを描画するライブラリです 下の行を実行するとノートブック上で画像がインライン表示されます\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ①学習用データを準備する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データは、Google社が[クリエイティブ・コモンズ ライセンス バージョン4.0](https://creativecommons.org/licenses/by/4.0/)で公開している[\"the Quick, Draw!\"データセット](https://quickdraw.withgoogle.com/data)を利用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データをダウンロードして、`./raw_data`ディレクトリに保存します。\n",
    "\n",
    "ちなみに、Jupyterノートブックでは、「`!`」を先頭につけると、シェルコマンドを実行できます(Pythonの機能ではありません)。出力をPythonで使ったり、Pythonの変数を引数に使ったりも出来るので便利です。ここでは`wget`コマンドを使ってファイルをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap'\n",
    "LABELS = [\n",
    "    'apple', 'bed', 'cat', 'dog', 'eye',\n",
    "    'fish', 'grass', 'hand', 'ice cream', 'jacket',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data ./raw_data\n",
    "for l in LABELS:\n",
    "    url = '{}/{}.npy'.format(URL, l)\n",
    "    !wget -NP raw_data \"$url\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各ラベルのデータファイルがダウンロードできていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードしたデータを読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {label: np.load('raw_data/{}.npy'.format(label)) for label in LABELS}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各データの数を確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, data in six.iteritems(raw_data):\n",
    "    print('{:10}: {}'.format(label, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ためしに「猫」の画像を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.reshape(raw_data['cat'][0], [28, 28]), cmap='gray_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、学習用と評価用のデータセットを準備します。\n",
    "\n",
    "1. ダウンロードしたデータセットのうち10万件を取り出す\n",
    "    - 数にばらつきがあると、学習で用いられる頻度がクラスごとに変わってしまいます\n",
    "2. それぞれ画像データと教師ラベルの組み合わせに変換する\n",
    "    - 教師ラベルは、クラス名の文字列(例:apple)ではなく、それぞれクラスごとに番号を割り当てます\n",
    "3. 学習用と評価用に7:3で分ける\n",
    "    - 学習に使われていないデータで精度の評価を行いたいため、評価用のデータは別に保存します\n",
    "4. ランダムにシャッフル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クラスごとに割り当てる教師ラベルの番号を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label_name in enumerate(LABELS):\n",
    "    print(u'番号: {}   ラベル名: {}'.format(i, label_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "for label_name, value in six.iteritems(raw_data):\n",
    "    label_index = LABELS.index(label_name)\n",
    "    print('proccessing label class {}: \"{}\"'.format(label_index, label_name))\n",
    "    value = np.asarray(value) / 255.\n",
    "    tr = value[:70000]\n",
    "    te = value[70000:100000]\n",
    "    train_data.extend(zip(tr, np.full(70000, label_index)))\n",
    "    test_data.extend(zip(te, np.full(30000, label_index)))\n",
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用と評価用のデータを、TFRecord形式のファイルに出力します。TFRecordは非同期のストリーミング読み込みが可能で、圧縮効率が高く、機械学習で用いられる大規模データセットの保存に向いています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = './data/train.tfr'\n",
    "test_filename  = './data/test.tfr'\n",
    "\n",
    "def get_example_proto(image, label):\n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image' : tf.train.Feature(float_list=tf.train.FloatList(value=image)),\n",
    "        'label' : tf.train.Feature(int64_list=tf.train.Int64List(value=label)),\n",
    "    })).SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の変換処理は5分ほどかかります。少々お待ちください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tfr_options = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.GZIP)\n",
    "with tf.python_io.TFRecordWriter(train_filename, tfr_options) as train_tfr, \\\n",
    "     tf.python_io.TFRecordWriter(test_filename, tfr_options) as test_tfr:\n",
    "    print('Converting train data...')\n",
    "    for data, label in train_data:\n",
    "        train_tfr.write(get_example_proto(data, [label]))\n",
    "    print('Converting test data...')\n",
    "    for data, label in test_data:\n",
    "        test_tfr.write(get_example_proto(data, [label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.tfr`と`test.tfr`が生成されていれば成功です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの準備が完了しました。生成したデータは後ほどS3にアップロードします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ②TensorFlowでモデルの定義プログラムを実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの実装には、TensorFlowを利用します。TensorFlowは、Google社を主体として開発されている、オープンソースの汎用的な分散数値演算ライブラリです。TensorFlowにはディープラーニング向けのライブラリが用意されており、現在世界で最も人気のディープラーニングフレームワークと言われています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の4つの関数を定義したプログラムを用意するだけで、Amazon SageMakerを使ってモデルの学習を行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def train_input_fn(training_dir, hyperparameters):\n",
    "    # 学習用の入力データを読み込みます\n",
    "\n",
    "def eval_input_fn(training_dir, hyperparameters):\n",
    "    # 評価用の入力データを読み込みます\n",
    "\n",
    "def serving_input_fn(hyperparameters):\n",
    "    # サービング(APIサーバにしたとき)用に受け取る入力データの形式を定義します\n",
    "\n",
    "def model_fn(features, labels, mode, hyperparameters):\n",
    "    # モデルの定義をします\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もう少し具体的には、`model_fn`の中で以下の3つを定義します。\n",
    "\n",
    "1. **モデル**: ニューラルネットワーク\n",
    "2. **誤差**: 教師データと予測結果がどの程度違ったのかを定式化する\n",
    "3. **最適化アルゴリズム**: 誤差を最小化するようにモデルを最適化するアルゴリズム\n",
    "\n",
    "つまり、入力データと、上記3つの定義を行うだけです。\n",
    "\n",
    "予め実装してあるので、簡単な解説を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `train_input_fn`、`eval_input_fn`の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_input_fn`、`eval_input_fn`の引数には、S3上の学習データがマウントされたディレクトリのパスと、ジョブの起動時に指定できるプログラムの挙動を制御するためのハイパーパラメータが渡されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def train_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, params, is_training=True)\n",
    "\n",
    "def eval_input_fn(training_dir, params):\n",
    "    return _input_fn(training_dir, params, is_training=False)\n",
    "\n",
    "def _input_fn(data_dir, params, is_training):\n",
    "    # ハイパーパラメータを取得します\n",
    "    batch_size  = params.get('batch_size', 96)\n",
    "    buffer_size = params.get('shuffle_buffer_size', 4096)\n",
    "    cmp_type    = params.get('tfrecord_compression_type', 'GZIP')\n",
    "    train_file  = params.get('train_tfrecord_file', 'train.tfr')\n",
    "    test_file   = params.get('test_tfrecord_file', 'test.tfr')\n",
    "\n",
    "    # 学習用データのパス\n",
    "    tfrecord = os.path.join(data_dir,\n",
    "        train_file if is_training else test_file)\n",
    "\n",
    "    # TFrecordの読み込みと、シャッフルやリピートなどを設定します\n",
    "    return (tf.data.TFRecordDataset(tfrecord, compression_type=cmp_type)\n",
    "        .map(_parse_example)\n",
    "        .shuffle(buffer_size)\n",
    "        .batch(batch_size)\n",
    "        .repeat(-1 if is_training else 1)\n",
    "        .make_one_shot_iterator()\n",
    "        .get_next())\n",
    "\n",
    "# 圧縮のためtf.train.Exampleに変換されているのでパースする関数です\n",
    "def _parse_example(example):\n",
    "    features = tf.parse_single_example(example,  {\n",
    "        'image': tf.FixedLenFeature([28, 28, 1], tf.float32),\n",
    "        'label': tf.FixedLenFeature([]         , tf.int64),\n",
    "    })\n",
    "    label = features.pop('label')\n",
    "    return features, label\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `serving_input_fn`の実装\n",
    "\n",
    "サービング（学習後の認識機能の提供）用の入力定義を行います。これはAPIサーバにデプロイしない場合も必要なので注意してください。\n",
    "\n",
    "以下では、入力データは、キーを`image`とし、浮動小数型のテンソルであることを定義しています。`[None, 28, 28, 1]`は、データの形状を示しています。\n",
    "\n",
    "TensorFlowで扱われるデータは全てTensor(テンソル)です。この場合、`image`テンソルはランク4のテンソルで、プログラム上では4次元配列で表現されます。各次元の長さは、None(可変長)、28、28、1です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def serving_input_fn(params):\n",
    "    return tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'image': tf.placeholder(tf.float32, [None, 28, 28, 1], name='image')\n",
    "    })()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `model_fn`の実装\n",
    "\n",
    "`model_fn`では、モデルと誤差と最適化の定義が必要でした。該当部分は以下のようになっています(一部省略しています)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    # ...\n",
    "\n",
    "    # 第一引数のfeaturesが入力データです\n",
    "    image = features['image']\n",
    "\n",
    "    # ...\n",
    "\n",
    "    #=========================================================\n",
    "    # ニューラルネットワークを定義します\n",
    "    #=========================================================\n",
    "    with tf.variable_scope('model', initializer=initializer):\n",
    "        x = image\n",
    "        x = tf.layers.conv2d(x, 32, 5, padding='SAME', activation=tf.nn.relu)\n",
    "        x = tf.layers.max_pooling2d(x, 2, 2, padding='SAME')\n",
    "        x = tf.layers.conv2d(x, 64, 5, padding='SAME', activation=tf.nn.relu)\n",
    "        x = tf.layers.max_pooling2d(x, 2, 2, padding='SAME')\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = tf.layers.dense(x, 1024, activation=tf.nn.relu)\n",
    "        x = tf.layers.dropout(x, rate=dropout_rate, training=is_training)\n",
    "        x = tf.layers.dense(x, 10)\n",
    "        logits = x\n",
    "\n",
    "    # 予測結果: クラスごとの離散確率分布、最も確率の高いクラスのインデクス\n",
    "    predictions = {\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "        'classes'      : tf.argmax(logits, axis=1),\n",
    "    }\n",
    "    \n",
    "    # ...\n",
    "\n",
    "    #=========================================================\n",
    "    # モデルの誤差を定義します\n",
    "    #=========================================================\n",
    "    with tf.variable_scope('losses'):\n",
    "        # クロスエントロピーを計算して誤差に追加します\n",
    "        cross_entropy_loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "            labels=labels, logits=logits)\n",
    "        \n",
    "        # モデルで追加された全ての誤差の総和を取得します\n",
    "        total_loss = tf.losses.get_total_loss()\n",
    "\n",
    "    # ...\n",
    "\n",
    "    #=========================================================\n",
    "    # モデルを学習(=パラメータを最適化)します\n",
    "    #=========================================================\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    \n",
    "    with tf.variable_scope('optimizer'), tf.control_dependencies(update_ops):\n",
    "        # total_loss(誤差の総和)が小さくなるようにパラメータを更新します\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        fit = optimizer.minimize(total_loss, global_step)\n",
    "\n",
    "    # ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの定義に関する詳細は、別途ノートブック`model.ipynb`で解説しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③Amazon SageMakerでモデルを学習する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker SDKを使い、プログラムとデータを指定して学習を実行します。\n",
    "\n",
    "まずは必要な情報を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "role    = sagemaker.get_execution_role()\n",
    "session = sagemaker.Session()\n",
    "bucket  = session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、データの保存先などの文字列を変数で定義します。ハンズオンでは共用のストレージを利用するため、**各自で保存先など変えて頂きます**。\n",
    "\n",
    "```python\n",
    "your_name = 'arata-furukawa' # 例\n",
    "```\n",
    "\n",
    "上記のように、`your_name`にご自身の名前など**他の人と被らない文字列**を入れてから、セルを実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_name = '' # 半角英数字とハイフンのみ利用可能です\n",
    "\n",
    "# 文字列チェック\n",
    "import re; assert re.match(r'^[0-9a-z-]+$', your_name) is not None\n",
    "\n",
    "def _s3(path):\n",
    "    return 's3://{}/doodle/model/{}/{}'.format(bucket, your_name, path)\n",
    "data_key_prefix = 'doodle/model/{}/data'.format(your_name)\n",
    "\n",
    "config = dict(\n",
    "    data_dir        = _s3('data'),\n",
    "    output_path     = _s3('export'),\n",
    "    checkpoint_path = _s3('ckpt'),\n",
    "    code_location   = _s3('src'),\n",
    "    public_dir      = _s3('public'),\n",
    "    job_name        = 'doodle-training-job-{}'.format(your_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in six.iteritems(config):\n",
    "    print('key: {:20}, value: {:20}'.format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記で設定したユニークなS3パスに、①で作成したデータセットをアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_data_dir = session.upload_data(\n",
    "    'data', # ローカルディレクトリ\n",
    "    bucket=bucket,\n",
    "    key_prefix=data_key_prefix)\n",
    "assert uploaded_data_dir == config['data_dir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの学習では、「エスティメータ(Estimator)」を利用します。 エスティメータは、モデルの学習や評価、保存やデプロイなどを行う抽象化されたインターフェイスです。\n",
    "\n",
    "用意したパスなどを設定として渡して、エスティメータを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    # ハイパーパラメータ\n",
    "    # ②で定義したプログラムの引数に渡されます\n",
    "    hyperparameters={\n",
    "        'save_summary_steps': 100,\n",
    "    },\n",
    "    \n",
    "    # 先程設定した、各データの保存先のパス\n",
    "    output_path     = config['output_path'],\n",
    "    checkpoint_path = config['checkpoint_path'],\n",
    "    code_location   = config['code_location'],\n",
    "    \n",
    "    # 学習用プログラムに関する設定\n",
    "    source_dir='./src',      # 学習用のプログラムが保存されたローカルディレクトリ\n",
    "    entry_point='doodle.py', # ②で定義した学習用プログラムのファイル名\n",
    "    framework_version='1.6', # 利用したいTensorFlowのバージョン\n",
    "    \n",
    "    training_steps=20000,\n",
    "    evaluation_steps=2000,\n",
    "    \n",
    "    # AWSでの実行に関する設定\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エスティメータに対して、学習用データのパス名を指定して`fit`関数を呼び出すと、学習ジョブが作成され、クラウド上でモデルの学習が実行されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この学習には10〜15分かかります。実行完了までしばらくお待ち下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator.fit(config['data_dir'], job_name=config['job_name'],\n",
    "              wait=True, run_tensorboard_locally=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみに、`run_tensorboard_locally`引数に`True`を渡すと、ノートブック上でTensorBoardが実行されます。TensorBoardに学習ログなどを表示するようにしてあるので、下記URLにアクセスして確認してみましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`https://(ノートブックのURL)/`[proxy/6006/](/proxy/6006/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ④学習したモデルをダウンロードして、Webアプリに組み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- S3からモデルデータをダウンロード・解凍\n",
    "- tfjs_converterでWeb向けに変換(ジョブで直接出力にするかも。ただしどのみちtar出力になっちゃうのでダウンロードして回答する必要あるしいらないかも)\n",
    "- 事前に用意したWebアプリをダウンロード・解凍\n",
    "- 適切なディレクトリに保存\n",
    "- Webアプリの設定ファイルを編集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデルは、エスティメータの`output_path`引数で指定した場所にGZIP圧縮されたTar書庫で保存されています。\n",
    "\n",
    "モデルをダウンロードして展開します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = '{}/{}/output/model.tar.gz'.format(config['output_path'], config['job_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./export ./model.tar.gz\n",
    "!aws s3 cp \"$model_url\" ./model.tar.gz\n",
    "!tar xvzf ./model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習ジョブで生成されたモデルは、SavedModelという形式です。TensorFlow.jsでブラウザ上で実行するために、Web用のフォーマットに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir ./export/Servo/* --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflowjs\n",
    "!mkdir -p ./webapp/saved_model_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_saved_model \\\n",
    "    --output_node_names='probabilities,classes' \\\n",
    "    --saved_model_tags=serve \\\n",
    "    ./export/Servo/* \\\n",
    "    ./webapp/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、Webアプリをダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./webapp\n",
    "!wget -O webapp.tar.gz https://github.com/maru-labo/doodle/releases/download/v0.0.2/tensorflowjs.doodle.marulabo.tar.gz\n",
    "!tar xvzf webapp.tar.gz -C webapp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⑤WebアプリをS3でホスティングして公開する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- S3上にアップロード\n",
    "- アクセスして確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync ./webapp $public_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('https://s3-{}.amazonaws.com/{}/index.html'.format(session.boto_region_name, public_dir[5:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
